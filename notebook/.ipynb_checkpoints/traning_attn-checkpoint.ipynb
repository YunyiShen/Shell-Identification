{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model identify if two images are the same turtle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try resnet based, also fine tune the last conv layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from os.path import join\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "from ShellRec.data_utils.prepare_photos import get_img_graph, split_graph\n",
    "from ShellRec.model import TurtleDiffAttnPool \n",
    "from ShellRec.dataset import TurtlePair \n",
    "from ShellRec.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing photo files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = get_img_graph(path = \"../dataset/BoxTurtle\", drop_p=[0.99,0])\n",
    "split_graph(all_train, save_path = \"../dataset\")\n",
    "_ = get_img_graph(path = \"../dataset/BoxTurtle_holdout\", \n",
    "                  file_to_save = \"../dataset/BoxTurtle_holdout.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## image transformations\n",
    "transform_train = timm.data.create_transform(224, is_training = True, \n",
    "                                   auto_augment = \"rand-m9-mstd0.5\")\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[.5,.5,.5], \n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_set = TurtlePair(data_file='../dataset/train.json',transform=transform_train)\n",
    "val_set = TurtlePair(data_file='../dataset/val.json',transform=transform_test)\n",
    "\n",
    "# Set up datasets and dataloaders\n",
    "train_loader = DataLoader( TurtlePair(data_file='../dataset/train.json', \n",
    "                                             transform=transform_train), \n",
    "                                             batch_size = 64)\n",
    "val_loader = DataLoader( TurtlePair(data_file='../dataset/val.json', \n",
    "                                           transform=transform_test), \n",
    "                                           batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model set up, use a pretrained model as backbone, and add a new head to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.set_dir('../pretrained/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = \"cpu\" #\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "\n",
    "model = TurtleDiffAttnPool() # use a vit backbone\n",
    "#model = TurtleDiff('resnet50') # use a resnet backbone\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "loss_list = train(model, optimizer, criterion, train_loader, val_loader, device, num_epochs,\n",
    "      save_path = \"../pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch]",
   "language": "python",
   "name": "conda-env-.conda-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
