{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model identify if two images are the same turtle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ShellRec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mShellRec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprepare_photos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_img_graph, split_graph\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mShellRec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshell_rec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TurtleDiff, TurtlePair, train\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ShellRec'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from os.path import join\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "from ShellRec.data_utils.prepare_photos import get_img_graph, split_graph\n",
    "from ShellRec.training.shell_rec import TurtleDiff, TurtlePair, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing photo files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = get_img_graph(path = \"../dataset/BoxTurtle\", drop_p=[0.99,0])\n",
    "split_graph(all_train, save_path = \"../dataset\")\n",
    "_ = get_img_graph(path = \"../dataset/BoxTurtle_holdout\", \n",
    "                  file_to_save = \"../dataset/BoxTurtle_holdout.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## image transformations\n",
    "transform_train = timm.data.create_transform(384, is_training = True, \n",
    "                                   auto_augment = \"rand-m9-mstd0.5\")\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize((384,384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[.5,.5,.5], \n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_set = TurtlePair(data_file='../dataset/train.json',transform=transform_train)\n",
    "val_set = TurtlePair(data_file='../dataset/val.json',transform=transform_test)\n",
    "\n",
    "# Set up datasets and dataloaders\n",
    "train_loader = DataLoader( TurtlePair(data_file='../dataset/train.json', \n",
    "                                             transform=transform_train), \n",
    "                                             batch_size = 128)\n",
    "val_loader = DataLoader( TurtlePair(data_file='../dataset/val.json', \n",
    "                                           transform=transform_test), \n",
    "                                           batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model set up, use a pretrained model as backbone, and add a new head to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.set_dir('../pretrained/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = \"cpu\" #\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "\n",
    "model = TurtleDiff('vit_base_patch16_384') # use a vit backbone\n",
    "#model = TurtleDiff('resnet50') # use a resnet backbone\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunyi/MIT/Turtle-Classifier/package/ShellRec/training/shell_rec.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(labels).to(device)\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_loader, val_loader, device, num_epochs,\n",
    "      save_path = \"../pretrained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
